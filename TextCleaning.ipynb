{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Smarikatripathi/NLP/blob/main/TextCleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Text Cleaning**"
      ],
      "metadata": {
        "id": "A6ndVuGRkL8F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Opening and Reading the text."
      ],
      "metadata": {
        "id": "OyYSl61WXN9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_file = open(\"/content/text for textcleaning.txt\")\n",
        "\n",
        "text = text_file.read()\n",
        "\n",
        "print(text)\n",
        "print(\"\\n\")\n",
        "\n",
        "print (len(text))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL2FU_L2TSa7",
        "outputId": "9792dff5-232c-4c94-9aa1-fc22cf4ac7b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<p>Hello!!! My name is SmArIkA Tripathi.I am a Computer Engineering student at <b>Pokhara University</b>. \n",
            "I LOVEEE learning new technologies, especially programming languages like Python, JavaScript, and Django. \n",
            "Currently, i am studying in my 7th semester, and i have been learning, practicing, and experimenting with \n",
            "different topics related to data science, machine learning, and web development. Sometimes, i feel \n",
            "confused  because there are sooo many resources on the internet, but i am still trying my best!!! \n",
            "In my free time, i enjoy watching tutorials, reading blogs, and exploring new tools & frameworks. \n",
            "I believe that learning never stops, and i am continuously improving myself by practicing coding \n",
            "and solving problems.</p>\n",
            "\n",
            "\n",
            "\n",
            "743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) HTML Tags removal:\n"
      ],
      "metadata": {
        "id": "MGkMAkiFkx7L"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "W2EV4YLBj7FX",
        "outputId": "a2587ee0-297b-43ce-fb40-0ef864ba51f7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Hello!!! My name is SmArIkA Tripathi.I am a Computer Engineering student at Pokhara University. \\nI LOVEEE learning new technologies, especially programming languages like Python, JavaScript, and Django. \\nCurrently, i am studying in my 7th semester, and i have been learning, practicing, and experimenting with \\ndifferent topics related to data science, machine learning, and web development. Sometimes, i feel \\nconfused  because there are sooo many resources on the internet, but i am still trying my best!!! \\nIn my free time, i enjoy watching tutorials, reading blogs, and exploring new tools & frameworks. \\nI believe that learning never stops, and i am continuously improving myself by practicing coding \\nand solving problems.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 79
        }
      ],
      "source": [
        "import re\n",
        "html_pattern = re.compile('<.*?>')\n",
        "text_data = re.sub(html_pattern, '', text)\n",
        "text_data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Upper and lower case inconsistency:**\n",
        "\n"
      ],
      "metadata": {
        "id": "_ZPW9LfmmkKU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = text_data.lower()\n",
        "text_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "SNDXo8M-kw4i",
        "outputId": "3df47e17-14b1-470f-bdf9-be0674e50e17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello!!! my name is smarika tripathi.i am a computer engineering student at pokhara university. \\ni loveee learning new technologies, especially programming languages like python, javascript, and django. \\ncurrently, i am studying in my 7th semester, and i have been learning, practicing, and experimenting with \\ndifferent topics related to data science, machine learning, and web development. sometimes, i feel \\nconfused  because there are sooo many resources on the internet, but i am still trying my best!!! \\nin my free time, i enjoy watching tutorials, reading blogs, and exploring new tools & frameworks. \\ni believe that learning never stops, and i am continuously improving myself by practicing coding \\nand solving problems.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) Remove Punctuations:**\n"
      ],
      "metadata": {
        "id": "Kr1zt803m2uB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = re.sub(r'[^\\w\\s]', '', text_data)\n",
        "text_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "9tsVCyKumx_7",
        "outputId": "96bef69b-e505-422c-ac58-613796b025b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello my name is smarika tripathii am a computer engineering student at pokhara university \\ni loveee learning new technologies especially programming languages like python javascript and django \\ncurrently i am studying in my 7th semester and i have been learning practicing and experimenting with \\ndifferent topics related to data science machine learning and web development sometimes i feel \\nconfused  because there are sooo many resources on the internet but i am still trying my best \\nin my free time i enjoy watching tutorials reading blogs and exploring new tools  frameworks \\ni believe that learning never stops and i am continuously improving myself by practicing coding \\nand solving problems\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**4) Remove words having length less than or equal to 2:**\n"
      ],
      "metadata": {
        "id": "ddMb-baonNPL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_data = ' '.join(word for word in text_data.split() if len(word)>2)\n",
        "text_data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "bWxgD6DxnQ7Y",
        "outputId": "625ed32d-3dce-4fc3-c15e-3676ecbb70ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'hello name smarika tripathii computer engineering student pokhara university loveee learning new technologies especially programming languages like python javascript and django currently studying 7th semester and have been learning practicing and experimenting with different topics related data science machine learning and web development sometimes feel confused because there are sooo many resources the internet but still trying best free time enjoy watching tutorials reading blogs and exploring new tools frameworks believe that learning never stops and continuously improving myself practicing coding and solving problems'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokenization**\n"
      ],
      "metadata": {
        "id": "fQgey-Dgnezv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Sentence Tokenizer:**\n"
      ],
      "metadata": {
        "id": "WLf2au-2nove"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_9EmxJhVn9JO",
        "outputId": "a7219399-3035-462b-c2da-1d529690c587"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "sent_tokenize(text_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4sih2V9nzet",
        "outputId": "e57c0dd6-2398-424b-db7b-9fc7116c70b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello name smarika tripathii computer engineering student pokhara university loveee learning new technologies especially programming languages like python javascript and django currently studying 7th semester and have been learning practicing and experimenting with different topics related data science machine learning and web development sometimes feel confused because there are sooo many resources the internet but still trying best free time enjoy watching tutorials reading blogs and exploring new tools frameworks believe that learning never stops and continuously improving myself practicing coding and solving problems']"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Word Tokenizer:**\n"
      ],
      "metadata": {
        "id": "A6AI2y5fnyiV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "tokenized_text= word_tokenize(text_data)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10wJiW4kodsz",
        "outputId": "fe474d2b-01e4-4870-8556-dfc4dc6ad616"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'name', 'smarika', 'tripathii', 'computer', 'engineering', 'student', 'pokhara', 'university', 'loveee', 'learning', 'new', 'technologies', 'especially', 'programming', 'languages', 'like', 'python', 'javascript', 'and', 'django', 'currently', 'studying', '7th', 'semester', 'and', 'have', 'been', 'learning', 'practicing', 'and', 'experimenting', 'with', 'different', 'topics', 'related', 'data', 'science', 'machine', 'learning', 'and', 'web', 'development', 'sometimes', 'feel', 'confused', 'because', 'there', 'are', 'sooo', 'many', 'resources', 'the', 'internet', 'but', 'still', 'trying', 'best', 'free', 'time', 'enjoy', 'watching', 'tutorials', 'reading', 'blogs', 'and', 'exploring', 'new', 'tools', 'frameworks', 'believe', 'that', 'learning', 'never', 'stops', 'and', 'continuously', 'improving', 'myself', 'practicing', 'coding', 'and', 'solving', 'problems']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3) WhitespaceTokenizer:**\n",
        "\n",
        "Based on white space, words are splitted."
      ],
      "metadata": {
        "id": "bP2bXviNnEwu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import WhitespaceTokenizer\n",
        "\n",
        "print(WhitespaceTokenizer().tokenize(text_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAjrS7eaopKK",
        "outputId": "45a69dac-5a7c-40f1-c9e4-80aa06956f05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'name', 'smarika', 'tripathii', 'computer', 'engineering', 'student', 'pokhara', 'university', 'loveee', 'learning', 'new', 'technologies', 'especially', 'programming', 'languages', 'like', 'python', 'javascript', 'and', 'django', 'currently', 'studying', '7th', 'semester', 'and', 'have', 'been', 'learning', 'practicing', 'and', 'experimenting', 'with', 'different', 'topics', 'related', 'data', 'science', 'machine', 'learning', 'and', 'web', 'development', 'sometimes', 'feel', 'confused', 'because', 'there', 'are', 'sooo', 'many', 'resources', 'the', 'internet', 'but', 'still', 'trying', 'best', 'free', 'time', 'enjoy', 'watching', 'tutorials', 'reading', 'blogs', 'and', 'exploring', 'new', 'tools', 'frameworks', 'believe', 'that', 'learning', 'never', 'stops', 'and', 'continuously', 'improving', 'myself', 'practicing', 'coding', 'and', 'solving', 'problems']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Stop word Removal**"
      ],
      "metadata": {
        "id": "6m09ac0No1eA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "stopwords = nltk.corpus.stopwords.words('english')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hVuiwz1JpSPT",
        "outputId": "163a5f53-9cb9-402b-82a4-3d218299733d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(stopwords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GDu_Kjc_pin-",
        "outputId": "103aea85-40e0-4430-830a-1dada0625023"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', \"he'd\", \"he'll\", 'her', 'here', 'hers', 'herself', \"he's\", 'him', 'himself', 'his', 'how', 'i', \"i'd\", 'if', \"i'll\", \"i'm\", 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it'd\", \"it'll\", \"it's\", 'its', 'itself', \"i've\", 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she'd\", \"she'll\", \"she's\", 'should', 'shouldn', \"shouldn't\", \"should've\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', \"they'd\", \"they'll\", \"they're\", \"they've\", 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', \"we'd\", \"we'll\", \"we're\", 'were', 'weren', \"weren't\", \"we've\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", 'your', \"you're\", 'yours', 'yourself', 'yourselves', \"you've\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(stopwords))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0L9PgO_pl6N",
        "outputId": "bd54f83e-3ca8-4e14-fb90-9753964c2645"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "198\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "text_data = re.sub(r'[^\\w\\s]', '', text_data) #punctuation removal\n",
        "\n",
        "from nltk.tokenize import word_tokenize\n",
        "tokenized_text = word_tokenize(text_data)\n",
        "tokenized_text = word_tokenize(text_data)\n",
        "print(tokenized_text)\n",
        "\n"
      ],
      "metadata": {
        "id": "f-9e0p92p9GP",
        "outputId": "d6784b94-982e-4db0-85e4-53eba05dada2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'name', 'smarika', 'tripathii', 'computer', 'engineering', 'student', 'pokhara', 'university', 'loveee', 'learning', 'new', 'technologies', 'especially', 'programming', 'languages', 'like', 'python', 'javascript', 'and', 'django', 'currently', 'studying', '7th', 'semester', 'and', 'have', 'been', 'learning', 'practicing', 'and', 'experimenting', 'with', 'different', 'topics', 'related', 'data', 'science', 'machine', 'learning', 'and', 'web', 'development', 'sometimes', 'feel', 'confused', 'because', 'there', 'are', 'sooo', 'many', 'resources', 'the', 'internet', 'but', 'still', 'trying', 'best', 'free', 'time', 'enjoy', 'watching', 'tutorials', 'reading', 'blogs', 'and', 'exploring', 'new', 'tools', 'frameworks', 'believe', 'that', 'learning', 'never', 'stops', 'and', 'continuously', 'improving', 'myself', 'practicing', 'coding', 'and', 'solving', 'problems']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "removed_stop_words_list = [word for word in tokenized_text if word not in stopwords]\n",
        "print(removed_stop_words_list)"
      ],
      "metadata": {
        "id": "4quenzz1tU5M",
        "outputId": "dce0d77e-113c-4475-9f44-9dd4fba8a724",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'name', 'smarika', 'tripathii', 'computer', 'engineering', 'student', 'pokhara', 'university', 'loveee', 'learning', 'new', 'technologies', 'especially', 'programming', 'languages', 'like', 'python', 'javascript', 'django', 'currently', 'studying', '7th', 'semester', 'learning', 'practicing', 'experimenting', 'different', 'topics', 'related', 'data', 'science', 'machine', 'learning', 'web', 'development', 'sometimes', 'feel', 'confused', 'sooo', 'many', 'resources', 'internet', 'still', 'trying', 'best', 'free', 'time', 'enjoy', 'watching', 'tutorials', 'reading', 'blogs', 'exploring', 'new', 'tools', 'frameworks', 'believe', 'learning', 'never', 'stops', 'continuously', 'improving', 'practicing', 'coding', 'solving', 'problems']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords.append('fmcg')\n",
        "len(stopwords)\n"
      ],
      "metadata": {
        "id": "9LfjB90It7K8",
        "outputId": "6a1c9872-376c-46cc-e056-784b540061c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "199"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "removed_stop_words_list = [word for word in tokenized_text if word not in stopwords]\n",
        "print(removed_stop_words_list)"
      ],
      "metadata": {
        "id": "ZWFyy9ROuEiv",
        "outputId": "8e228417-a6bd-44e3-fc7c-1a3f458e315f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'name', 'smarika', 'tripathii', 'computer', 'engineering', 'student', 'pokhara', 'university', 'loveee', 'learning', 'new', 'technologies', 'especially', 'programming', 'languages', 'like', 'python', 'javascript', 'django', 'currently', 'studying', '7th', 'semester', 'learning', 'practicing', 'experimenting', 'different', 'topics', 'related', 'data', 'science', 'machine', 'learning', 'web', 'development', 'sometimes', 'feel', 'confused', 'sooo', 'many', 'resources', 'internet', 'still', 'trying', 'best', 'free', 'time', 'enjoy', 'watching', 'tutorials', 'reading', 'blogs', 'exploring', 'new', 'tools', 'frameworks', 'believe', 'learning', 'never', 'stops', 'continuously', 'improving', 'practicing', 'coding', 'solving', 'problems']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Stemming & Lemmatization**"
      ],
      "metadata": {
        "id": "Jh50tdOgu8oz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**1) Stemming:**\n",
        "\n",
        "\n",
        "Stemming is the process of converting/reducing the inflected words to their root form. In this method, the suffixes are removed from the inflected word so that it becomes the root.\n",
        "\n",
        "For eg. From the word “Going”, “ing” suffix will get removed and the inflected word “Going” will become “Go” which is the root form.\n"
      ],
      "metadata": {
        "id": "7nA3mwJpvMcq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "stemmed_words = []\n",
        "\n",
        "for word in tokenized_text:\n",
        "    stemmed_words.append(stemmer.stem(word))\n",
        "\n",
        "print(stemmed_words)\n"
      ],
      "metadata": {
        "id": "mAQ2nUBTvZPk",
        "outputId": "253e4f93-1d77-4778-e27e-335f8e23e3e2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'name', 'smarika', 'tripathii', 'comput', 'engin', 'student', 'pokhara', 'univers', 'lovee', 'learn', 'new', 'technolog', 'especi', 'program', 'languag', 'like', 'python', 'javascript', 'and', 'django', 'current', 'studi', '7th', 'semest', 'and', 'have', 'been', 'learn', 'practic', 'and', 'experi', 'with', 'differ', 'topic', 'relat', 'data', 'scienc', 'machin', 'learn', 'and', 'web', 'develop', 'sometim', 'feel', 'confus', 'becaus', 'there', 'are', 'sooo', 'mani', 'resourc', 'the', 'internet', 'but', 'still', 'tri', 'best', 'free', 'time', 'enjoy', 'watch', 'tutori', 'read', 'blog', 'and', 'explor', 'new', 'tool', 'framework', 'believ', 'that', 'learn', 'never', 'stop', 'and', 'continu', 'improv', 'myself', 'practic', 'code', 'and', 'solv', 'problem']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2) Lemmatization:**\n",
        "\n",
        "\n",
        "It is where the words are converted to their root forms by understanding the context of the word in the sentence.\n",
        "\n",
        "In Stemming, the root word which we get after conversion is called a **stem**.\n",
        "\n",
        "Whereas, it is called a **lemma** in Lemmatization."
      ],
      "metadata": {
        "id": "ZrxZlRhbzt81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.corpus import wordnet"
      ],
      "metadata": {
        "id": "x0-r4T2f07ZT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_words = [lemmatizer.lemmatize(word) for word in tokenized_text]\n",
        "print(lemmatized_words)"
      ],
      "metadata": {
        "id": "Hp3XQ-8B1HVs",
        "outputId": "0e6aacce-74cc-4a9d-e154-ab8ad50f72c3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'name', 'smarika', 'tripathii', 'computer', 'engineering', 'student', 'pokhara', 'university', 'loveee', 'learning', 'new', 'technology', 'especially', 'programming', 'language', 'like', 'python', 'javascript', 'and', 'django', 'currently', 'studying', '7th', 'semester', 'and', 'have', 'been', 'learning', 'practicing', 'and', 'experimenting', 'with', 'different', 'topic', 'related', 'data', 'science', 'machine', 'learning', 'and', 'web', 'development', 'sometimes', 'feel', 'confused', 'because', 'there', 'are', 'sooo', 'many', 'resource', 'the', 'internet', 'but', 'still', 'trying', 'best', 'free', 'time', 'enjoy', 'watching', 'tutorial', 'reading', 'blog', 'and', 'exploring', 'new', 'tool', 'framework', 'believe', 'that', 'learning', 'never', 'stop', 'and', 'continuously', 'improving', 'myself', 'practicing', 'coding', 'and', 'solving', 'problem']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lemmatizer is unable to normalize the words “going” and “went” into their root forms.**"
      ],
      "metadata": {
        "id": "zQHzZyay1WBU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is because we have not passed the context to it.\n",
        "\n",
        "Part of speech “pos” is the parameter which we need to specify. By default it is NOUN.\n"
      ],
      "metadata": {
        "id": "NQ4J6sOx1biq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.stem import WordNetLemmatizer\n",
        "wordnet_lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "lemmatized_verbs = [lemmatizer.lemmatize(word, pos='v') for word in tokenized_text]\n",
        "print(lemmatized_verbs)\n"
      ],
      "metadata": {
        "id": "2ar6qcWU1ryy",
        "outputId": "e44c1f56-8b61-4485-e795-7671c9a18c60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hello', 'name', 'smarika', 'tripathii', 'computer', 'engineer', 'student', 'pokhara', 'university', 'loveee', 'learn', 'new', 'technologies', 'especially', 'program', 'languages', 'like', 'python', 'javascript', 'and', 'django', 'currently', 'study', '7th', 'semester', 'and', 'have', 'be', 'learn', 'practice', 'and', 'experiment', 'with', 'different', 'topics', 'relate', 'data', 'science', 'machine', 'learn', 'and', 'web', 'development', 'sometimes', 'feel', 'confuse', 'because', 'there', 'be', 'sooo', 'many', 'resources', 'the', 'internet', 'but', 'still', 'try', 'best', 'free', 'time', 'enjoy', 'watch', 'tutorials', 'read', 'blog', 'and', 'explore', 'new', 'tool', 'frameworks', 'believe', 'that', 'learn', 'never', 'stop', 'and', 'continuously', 'improve', 'myself', 'practice', 'cod', 'and', 'solve', 'problems']\n"
          ]
        }
      ]
    }
  ]
}